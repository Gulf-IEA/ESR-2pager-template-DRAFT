---
title: "BSB 2024 bottom temp update"
output: html_document
date: "`r Sys.Date()`"
author: "Abigail Tyrell"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
`%>%` <- magrittr::`%>%`

library(tidyverse)
library(tidync)
library(sf)

```

## Data

### Get data through 2019 from ERDDAP
Hubert's data product is a composite before 1993, and from 1993-2019 it is the same as GLORYS.This data can eventually be pulled directly from ERDDAP, but in the current testing stage it needs to be manually downloaded. 
```{r}
# url <- "http://nefsctest.nmfs.local:8080/erddap/griddap/duPontavice_bottom_temp_local.csv?sea_water_temperature_at_sea_floor%5B(1989-01-01T00:00:00Z):1:(2019-04-01T00:00:00Z)%5D%5B(35.9166666666667):1:(44.4166666666667)%5D%5B(-75.9166666666667):1:(-65.75)%5D"

# data <- read.csv(url) # this should work but seems like NEFSC is choking the download
data <- read.csv(here::here("data-raw/duPontavice_bottom_temp_local_4d04_943c_b2ef.csv"))

# data2 <- data[[2]][-1,] %>%
data2 <- data[-1,] %>%
  tidyr::drop_na() %>%
  dplyr::mutate(dplyr::across(2:4, as.numeric),
                dplyr::across(1, lubridate::as_date),
                year = lubridate::year(time),
                month = lubridate::month(time)) %>%
  dplyr::filter(month %in% 2:3) %>%
  dplyr::rename(value = sea_water_temperature_at_sea_floor)
```

### Recent GLORYS data from 2020-2023
Recent years of GLORYS data are added from a separate data pull. 

```{r}
files <- list.files(path = here::here("data-raw/2024_update"), 
                    pattern = "^glo",
                    full.names = TRUE)
for(i in files){
  this_dat <- tidync(i) %>%
  hyper_tibble(force = TRUE)

### get time info and add to tibble ----
tunit <- ncmeta::nc_atts(i, "time") %>%
  dplyr::filter(name == "units") %>%
  tidyr::unnest(cols = c(value))

this_dat2 <- this_dat %>%
  dplyr::mutate(month = RNetCDF::utcal.nc(tunit$value, .data$time)[,"month"],
                year = RNetCDF::utcal.nc(tunit$value, .data$time)[,"year"]) %>%
  # filter to feb and march
  dplyr::filter(month %in% 2:3) %>%
  dplyr::rename(value = bottomT)

data2 <- rbind(data2, this_dat2)
# time col gets weird in join depending on if the files were formatted the same
# but month and year cols are fine
}
```

### BSB Shapefile
```{r}

shape_bsb <- read_sf(here::here('data-raw/bsb_shape.shp')) %>%
  st_transform(4140)
```

## Analysis

```{r}
# calculate monthly mean
data3 <- data2 %>%
  group_by(longitude, latitude, year, month) %>%
  summarise(bt_temp = mean(value, na.rm = TRUE))

## cut to area of interest ----
# this could possibly be done quicker with raster::mask

# Extract the grid and create a spatial object for each grid cell (center of the grid cell)
glorys_grid <- unique(data3[c("longitude","latitude")]) %>%
  as.data.frame() %>%
  bind_cols(geometry = st_as_sf(.,coords = c("longitude", "latitude"), crs = st_crs(shape_bsb)),.)

# SPATIAL JOIN - identify cells whose the centers is included or intersect the BSB area
cell_intersects <- st_join(shape_bsb, glorys_grid, join = st_intersects) %>%
  as.data.frame()

# select grid cells within the BSB areas and calculate the winter mean for each area
data_bt_bsb <- inner_join(data3, cell_intersects, by = c("longitude","latitude")) %>%
  filter(month %in% c(2, 3)) %>%
  group_by(Region, year) %>%
  summarise(mean = mean(bt_temp, na.rm = TRUE),
            count = n(),
            sd = sd(bt_temp, na.rm = TRUE),
            se = sd/sqrt(count))

# select grid cells within the BSB areas and calculate the winter mean for entire area
data_bt_bsb_all <- inner_join(data3, cell_intersects, by = c("longitude","latitude")) %>%
  # filter(month %in% c(2, 3)) %>%
  group_by(year) %>%
  summarise(mean = mean(bt_temp, na.rm = TRUE),
            count = n(),
            sd = sd(bt_temp, na.rm = TRUE),
            se = sd/sqrt(count))

## create results tibble ----
results <- rbind(data_bt_bsb,
                 data_bt_bsb_all %>%
                   dplyr::mutate(Region = "All"))
write.csv(results,
          here::here("data", paste0("bt_update_", Sys.Date(), ".csv")))
```

## Compare to past data
```{r, echo = FALSE}
dat <- read.csv(here::here("data/bsb_bt_temp_nmab_1959-2022.csv"))
sdat <- read.csv(here::here("data/bsb_bt_temp_smab_1959-2022.csv"))

dat2 <- dat %>%
  dplyr::bind_rows(sdat) %>%
  dplyr::mutate(type = "2023 data") %>%
  dplyr::bind_rows(results %>%
                     dplyr::mutate(type = "2024 data"))

dat2 %>%
  dplyr::filter(Region != "All") %>%
  ggplot2::ggplot(ggplot2::aes(x = year,
                               y = mean,
                               color = Region,
                               shape = type,
                               lty = type)) +
  ggplot2::geom_point() +
  ggplot2::geom_path() + 
  ggplot2::theme_bw() +
  ggplot2::xlim(c(1989, 2023)) +
  ggplot2::labs(title = "Mean bottom temperature in Feb & March")
```
